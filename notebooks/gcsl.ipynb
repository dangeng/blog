{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m0j9Anlrb8zV"
   },
   "source": [
    "# Goal-Conditioned Supervised Learning (GCSL)\n",
    "\n",
    "<a href=\"https://ibb.co/gz3HWFD\"><img src=\"https://i.ibb.co/J5K0pFz/gcsl-figure-arxiv.png\" alt=\"gcsl-figure-arxiv\" border=\"0\" /></a>\n",
    "\n",
    "This notebook provides a brief introduction to goal-conditioned supervised learning (GCSL), as introduced in \n",
    "> Dibya Ghosh, Abhishek Gupta, Justin Fu, Ashwin Reddy, Coline Devin, Benjamin Eysenbach, Sergey Levine. *Learning To Reach Goals via Iterated Supervised Learning.*\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/notdibya/gcsl/blob/master/GCSLDemo.ipynb\" target=\"_parent\"><img src=\"https://camo.githubusercontent.com/52feade06f2fecbf006889a904d221e6a730c194/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667\" alt=\"Open In Colab\" data-canonical-src=\"https://colab.research.google.com/assets/colab-badge.svg\"></a>\n",
    "\n",
    "GCSL is a simple algorithm in which an agent continually relabels and imitates its own experience to progressively learn goal-reaching behaviors. Each iteration, the agent collects new trajectories, creates examples of optimal behavior using hindsight relabelling from these trajectories, and uses supervised learning to maximize the likelihood of these optimal actions under the current policy to improve it.\n",
    "\n",
    "We will develop a simple and concrete instantiation of the GCSL algorithm for solving goal-reaching tasks on a simple 2d navigation task with discrete actions to explain the algorithm. For a codebase with more complete features, please see the Github repository linked below.\n",
    "\n",
    "Other useful links:\n",
    "- [ArXiv paper](https://arxiv.org/abs/1912.06088)\n",
    "- [Github](https://github.com/notdibya/gcsl/)\n",
    "- [Interactive Colab](https://colab.research.google.com/github/notdibya/gcsl/blob/master/GCSLDemo.ipynb) (follow along with the code)\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AaRJqidtb7_V"
   },
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y3mSscqSiUBu"
   },
   "source": [
    "## The Environment\n",
    "We use a navigation task in a room to illustrate GCSL. The agent can take one of 5 actions: go up, right, down, left or stay still.\n",
    "\n",
    "The environment defined below is simply a normal Gym env, but with one new function:\n",
    "- `env.sample_goal()`: To define the goal reaching task, we need a notion of what goals the agent should try to reach. This function samples one such *desired goal*. In this case, a goal position is chosen randomly in the room.\n",
    "\n",
    "We also implement some helper functions, for collecting and visualizing data from this environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "class Pointmass(gym.Env):\n",
    "    ... # See Colab / IPynb for details about hidden code\n",
    "    \n",
    "def plot_trajectory(trajectory, ax=None):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "iYMzlA9kd1C-"
   },
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "\n",
    "import gym\n",
    "\n",
    "class Pointmass(gym.Env):\n",
    "    def __init__(self):\n",
    "        # 2-d coordinates\n",
    "        self.observation_space = gym.spaces.Box(-1, 1, shape=(2,), dtype=np.float32)\n",
    "        self.position = np.zeros(2) \n",
    "        # Up, Right, Down, Left, Stay\n",
    "        self.action_space = gym.spaces.Discrete(5)\n",
    "\n",
    "    def reset(self):\n",
    "        self.position = np.zeros(2)\n",
    "        return self.position\n",
    "\n",
    "    def action_to_direction(self, a):\n",
    "        actions = [\n",
    "                   np.array([0, 1]), # Up\n",
    "                   np.array([1, 0]), # Right\n",
    "                   np.array([0, -1]), # Down\n",
    "                   np.array([-1, 0]), # Left,\n",
    "                   np.array([0, 0]), # Stay still\n",
    "        ]\n",
    "        return actions[a]\n",
    "\n",
    "    def step(self, a):\n",
    "        direction = self.action_to_direction(a)\n",
    "        step = 0.05 * direction + np.random.randn() * 0.01 # Take a noisy step in direction\n",
    "        self.position = self.position + step\n",
    "        self.position = np.clip(self.position, -1, 1) # Clip to prevent object from escaping\n",
    "        return (self.position, # State\n",
    "              0,     # Reward (not necessary for GCSL)\n",
    "              False, # Done flag\n",
    "              dict()) # Additional info \n",
    "\n",
    "    def sample_goal(self):\n",
    "        return np.random.rand(2) * 2 - 1 # Sample uniformly from [-1, 1]\n",
    "\n",
    "\n",
    "def plot_trajectory(trajectory, ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    # Draw path\n",
    "    ax.plot(*trajectory['states'].T)\n",
    "    # Draw goal\n",
    "    ax.scatter(trajectory['desired_goal'][0], trajectory['desired_goal'][1], s=400, marker='*')\n",
    "    # Draw boundary\n",
    "    ax.vlines([-1, 1], -1, 1)\n",
    "    ax.hlines([-1, 1], -1, 1)\n",
    "\n",
    "    ax.set_xlim(-1.05, 1.05)\n",
    "    ax.set_ylim(-1.05, 1.05)\n",
    "    ax.axis('off')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d3kny1ATEvD8"
   },
   "source": [
    "## The Agent\n",
    "\n",
    "Our agent must choose an action to take, given three pieces of information\n",
    "1. The **state** the agent is currently at\n",
    "2. The **goal** the agent is trying to get to\n",
    "3. The amount of time the agent has left to reach the goal (the **horizon**)\n",
    "\n",
    "Below, we show an implementation of a *random* agent for illustration.\n",
    "The agent interacts with the environment, through `sample_trajectory` as defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ADPSIvYTggLq"
   },
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    def get_action(self, state, goal, horizon):\n",
    "        return np.random.choice(5) # Choose randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BuOS3Qu0JJiO"
   },
   "source": [
    "At the beginning of each episode, we choose a desired goal (according to `env.sample_goal()`). The agent interacts with the environment (in the typical RL fashion) trying to reach this goal by the last timestep of this episode (total 50 timesteps).\n",
    "\n",
    "We implement \n",
    "- `sample_trajectory(env, agent)` which executes an episode according to the above logic\n",
    "- `evaluate_agent(env, agent)` and `visualize_agent(env, agent)` which repeatedly collect episodes using the above function to provide a summary of how well the agent can reach goals in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "j81noQG7JBTz"
   },
   "outputs": [],
   "source": [
    "def sample_trajectory(env, agent, T=50):\n",
    "    # Sample a target goal (fixed for episode)\n",
    "    desired_goal = env.sample_goal()\n",
    "\n",
    "    # Default control loop\n",
    "    state = env.reset()\n",
    "    states = list()\n",
    "    actions = list()\n",
    "    for i in range(T):\n",
    "        states.append(state)\n",
    "\n",
    "        action = agent.get_action(state=state,\n",
    "                                  goal=desired_goal,\n",
    "                                  horizon=np.array(T-i, dtype=float))\n",
    "        actions.append(action)\n",
    "\n",
    "        state, _, _, _ = env.step(action)\n",
    "\n",
    "    return {\n",
    "      'states': np.array(states),  \n",
    "      'actions': np.array(actions),\n",
    "      'desired_goal': desired_goal,\n",
    "}\n",
    "\n",
    "def evaluate_agent(env, agent, n=50):\n",
    "    # Collects n episodes, and logs average distance to goal\n",
    "    ...\n",
    "\n",
    "def visualize_agent(env, agent):\n",
    "    # Collects 5 episodes, and visualizes the paths taken\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "\n",
    "def evaluate_agent(env, agent, n=50):\n",
    "    distances = []\n",
    "    for _ in range(n):\n",
    "        trajectory = sample_trajectory(env, agent)\n",
    "        distances.append(np.linalg.norm(trajectory['states'][-1] - trajectory['desired_goal']))\n",
    "    print('Median Distance to Goal:  %.3f'% np.median(distances))\n",
    "    print('Min Distance to Goal:  %.3f'% np.min(distances))\n",
    "    print('Max Distance to Goal:  %.3f'% np.max(distances))\n",
    "\n",
    "def visualize_agent(env, agent):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "    for ax in axes:\n",
    "        plot_trajectory(sample_trajectory(env, agent), ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "zUYOFv236K-y",
    "outputId": "3af5952b-1d87-42ec-aae0-33da27e0de37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Distance to Goal:  0.725\n",
      "Min Distance to Goal:  0.161\n",
      "Max Distance to Goal:  1.344\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f861cd8dda0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = Pointmass()\n",
    "agent = RandomAgent()\n",
    "\n",
    "evaluate_agent(env, agent)\n",
    "visualize_agent(env, agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RGWsBwD3HlB2"
   },
   "source": [
    "### A Neural Network Agent\n",
    "\n",
    "We will learn an agent whose policy is determined by a neural network.\n",
    "\n",
    "This agent takes in the state, goal, and horizon; concatenates them all together; and feeds this input into a neural network with two hidden layers of size 100 each. The neural network outputs logits for each action.\n",
    "\n",
    "The agent will sample according to the logits to output the action.\n",
    "\n",
    "This agent can be implemented using the code below in Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "EzT1kJLP9LcD"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NNAgent(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "          nn.Linear(5, 100), # Input 2 (state) + 2 (goal) + 1 (horizon)\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(100, 100),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(100, 5), # Output: 5 actions\n",
    "          )\n",
    "\n",
    "    def forward(self, state, goal, horizon):\n",
    "        horizon = horizon / 50 # Normalize between [0, 1]\n",
    "        x = torch.cat([state, goal, horizon], -1)\n",
    "        logits = self.net(x)\n",
    "        return logits\n",
    "\n",
    "    def get_action(self, state, goal, horizon):\n",
    "        # Put into PyTorch Notation\n",
    "        state_torch, goal_torch, horizon_torch = to_torch(state, goal, horizon)\n",
    "        logits_torch = self.forward(state_torch, goal_torch, horizon_torch)[0]\n",
    "        probabilities_torch = torch.softmax(logits_torch, -1)\n",
    "        probabilities = probabilities_torch.detach().numpy()\n",
    "\n",
    "        return np.random.choice(5, p=probabilities)\n",
    "  \n",
    "\n",
    "def to_torch(state, goal, horizon):\n",
    "    state_torch = torch.tensor(state, dtype=torch.float32)[None]\n",
    "    goal_torch = torch.tensor(goal, dtype=torch.float32)[None]\n",
    "    horizon_torch = torch.tensor(horizon, dtype=torch.float32)[None, None]\n",
    "    return state_torch, goal_torch, horizon_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below shows the performance of a randomly initialized neural network agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "K1B_Gi_2-hTG",
    "outputId": "8bef997b-22f5-4254-c158-410831bd8379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Distance to Goal:  0.767\n",
      "Min Distance to Goal:  0.149\n",
      "Max Distance to Goal:  1.789\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f861cd83f28>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = NNAgent()\n",
    "visualize_agent(env, agent)\n",
    "evaluate_agent(env, agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've established the basics of what an *agent* is, how it interacts with the environment, and how to evaluate the agent, let's actually train a policy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RhIQ91GoKTbN"
   },
   "source": [
    "## Goal-Conditioned Supervised Learning\n",
    "\n",
    "\n",
    "Goal-conditioned supervised learning (GCSL) uses the principle of hindsight to turn data collected by the policy into \"optimal\" data that can be imitated using a supervised learning objective (behavioral cloning).\n",
    "\n",
    "Suppose the agent has just executed the following episode. It was commanded to reach the goal $g^*$, and ends up seeing the following states and taking the following actions\n",
    "\n",
    "$$s_0, a_0, s_1, a_1, s_2, \\dots s_{50}, a_{50}$$\n",
    "\n",
    "The agent might have done a terrible job at reaching $g^*$. It could be that the final state $s_{50}$ and $g^*$ are on opposite sides of the room. However, we know that the agent was able to successfully reach $s_{50}$, and we can use the data collected in the trajectory to teach the agent how to better get to $s_{50}$. For that matter, the agent was also able to reach $s_{49}, s_{48}, \\dots$, and we can use this data to learn how to reach all of these states  more accurately.\n",
    "\n",
    "More precisely, consider any two timesteps $t_1$ and $t_2$ ($t_1 < t_2$). We know that after the agent took action $a_{t_1}$ in state $s_{t_1}$, it reached the state $s_{t_2}$ after $t_2-t_1$ timesteps. This means that we can treat $a_{t_1}$ as being **optimal** behavior at $s_{t_1}$ when trying to reach $s_{t_2}$ in $t_2 - t_1$ timesteps.\n",
    "\n",
    "\n",
    "This statement is true for any two timesteps $t_1 < t_2$.\n",
    "\n",
    "\n",
    "The algorithm **GCSL** attempts to imitate all of these synthesized optimal behaviors by performing maximum-likelihood estimation (MLE) via supervised learning.\n",
    "\n",
    "$$\\max \\log \\pi(a_{t_1} | s=s_{t_1}, g=s_{t_2}, h=t_2-t_1)$$\n",
    "\n",
    "When the environment has discrete actions, MLE corresponds to a supervised classification  problem: simply treat $a_{t_1}$ as the ground truth label $y$ for a classification problem with input $x = (s=s_{t_1}, g=s_{t_2}, h=t_2-t_1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KFE4V2GGC5LF"
   },
   "source": [
    "### Pseudocode\n",
    "\n",
    "How does this translate in practice?\n",
    "\n",
    "Suppose that the agent has already collected some trajectories in its buffer.\n",
    "```\n",
    "buffer = []\n",
    "for i in range(10):\n",
    "  buffer.append(sample_trajectory(env, agent))\n",
    "```\n",
    "\n",
    "When training the policy, we will sample a trajectory randomly from the dataset\n",
    "```\n",
    "trajectory = buffer[np.random.choice(len(buffer))]\n",
    "```\n",
    "Choose two time-steps randomly on this path $t_1 < t_2$ (remember, hindsight works for any trajectory and any such pair).\n",
    "```\n",
    "t1, t2 = np.random.randint(0, 50, size=2)\n",
    "t1, t2 = min([t1, t2]), max([t1, t2])\n",
    "```\n",
    "\n",
    "If we define\n",
    "- `s` to be the state at t1\n",
    "- `a` to be the action at t1\n",
    "- `g` to be the state at t2\n",
    "- `h` to be t2 - t1\n",
    "\n",
    "```\n",
    "s = trajectory['states'][t1]\n",
    "a = trajectory['actions'][t1]\n",
    "g = trajectory['states'][t2]\n",
    "h = t2 - t1\n",
    "```\n",
    "\n",
    "\n",
    "Then `a` is a good action to go from `s` to `g` in `h` timesteps.\n",
    "\n",
    "Because of this, we can treat it as expert data for `agent(state=s, goal=g, horizon=h)`\n",
    "\n",
    "\n",
    "```\n",
    "  loss = nn.functional.cross_entropy(agent(s, g, h), a)\n",
    "```\n",
    "\n",
    "This leads to the following code-block that fully describes the GCSL algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zRhhZTINC20w",
    "outputId": "a1904a83-379b-49f3-8129-9b953c362f97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Episode 0 #####\n",
      "Median Distance to Goal:  0.915\n",
      "Min Distance to Goal:  0.158\n",
      "Max Distance to Goal:  1.686\n",
      "##### Episode 40 #####\n",
      "Median Distance to Goal:  0.202\n",
      "Min Distance to Goal:  0.041\n",
      "Max Distance to Goal:  0.624\n",
      "##### Episode 80 #####\n",
      "Median Distance to Goal:  0.091\n",
      "Min Distance to Goal:  0.013\n",
      "Max Distance to Goal:  0.329\n",
      "##### Episode 120 #####\n",
      "Median Distance to Goal:  0.106\n",
      "Min Distance to Goal:  0.011\n",
      "Max Distance to Goal:  0.276\n",
      "##### Episode 160 #####\n",
      "Median Distance to Goal:  0.083\n",
      "Min Distance to Goal:  0.004\n",
      "Max Distance to Goal:  0.223\n",
      "##### Episode 200 #####\n",
      "Median Distance to Goal:  0.093\n",
      "Min Distance to Goal:  0.012\n",
      "Max Distance to Goal:  0.204\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f861cd82be0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GCSL in a single cell\n",
    "\n",
    "# Create agent and optimizer\n",
    "agent = NNAgent()\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(agent.parameters(), lr=learning_rate)\n",
    "\n",
    "buffer = []\n",
    "n_episodes = 201\n",
    "n_steps_per_episode = 500\n",
    "\n",
    "for episode in range(n_episodes):\n",
    "    # Collect more data and put it in the replay buffer\n",
    "    new_trajectory = sample_trajectory(env, agent)\n",
    "    buffer.append(new_trajectory)\n",
    "\n",
    "    # GCSL optimization  \n",
    "    for step in range(n_steps_per_episode):\n",
    "\n",
    "        # Sample a trajectory and timesteps\n",
    "        trajectory = buffer[np.random.choice(len(buffer))]\n",
    "        t1, t2 = np.random.randint(0, 50, size=2)\n",
    "        t1, t2 = min([t1, t2]), max([t1, t2])\n",
    "\n",
    "        # Create optimal ((s, g, h), a) data\n",
    "        s = trajectory['states'][t1]\n",
    "        g = trajectory['states'][t2]\n",
    "        h = t2 - t1\n",
    "        a = trajectory['actions'][t1]\n",
    "\n",
    "        s, g, h = to_torch(s, g, h)\n",
    "        a = torch.tensor(a)[None]\n",
    "\n",
    "        # Optimize agent(s, g, h) to imitate action a \n",
    "        optimizer.zero_grad()\n",
    "        loss = nn.functional.cross_entropy(agent(s, g, h), a)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print agent performance once in a while\n",
    "    if episode % 40 == 0:\n",
    "        print('##### Episode %d #####'%episode)\n",
    "        evaluate_agent(env, agent)\n",
    "\n",
    "visualize_agent(env, agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z-wm1ClwR-ES"
   },
   "source": [
    "When you run the previous cell, you should see the GCSL agent learning how to reach all the states in the room! And that's it!\n",
    "\n",
    "If you're interested in learning more about how *why* this simple procedure works, check out our [paper](https://arxiv.org/abs/1912.06088). If you're looking to apply the algorithm on larger domains, check out our [Github repository](https://github.com/notdibya/gcsl)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GCSLDemo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
